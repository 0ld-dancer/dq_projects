{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project we will explore the dataset collected from [Hacker News Posts](https://news.ycombinator.com). Here everyone can submit their post, get comments and votes. \n",
    "\n",
    "More specifically, we are going to find out what type of the posts is more popular in terms of comments and points. \n",
    "\n",
    "Afterwards we'll search for the best period of the day (CET) to submit your post to get as much as possible of comments or points.\n",
    "\n",
    "Our dataset contains following columns:\n",
    "* `id`: The unique identifier from Hacker News for the post\n",
    "* `title`: The title of the post\n",
    "* `url`: The URL that the posts links to, if the post has a URurl: The URL that the posts links to, if the post has a URL\n",
    "* `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "* `num_comments`: The number of comments that were made on the post\n",
    "* `author`: The username of the person who submitted the post\n",
    "* `created_at`: The date and time at which the post was submitted\n",
    "\n",
    "[Here](https://www.kaggle.com/aquaregis32/exploring-hacker-news-posts) you can find the dataset and its documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we are openning and transforming our dataset into a suitable format: a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "from dateutil import tz\n",
    "\n",
    "opened = open('hacker_news.csv')\n",
    "read = reader(opened)\n",
    "hn = list(read)\n",
    "#extracting header\n",
    "header = hn[0]\n",
    "#saving the lines\n",
    "hn = hn[1:]\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "\n",
      "\n",
      "Dataset contains : \n",
      "Rows 293119 \n",
      "Columns 7\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_cols=False):\n",
    "    #printing the asked number of lines\n",
    "    for row in dataset[start:end]:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    #returning data about the dataset\n",
    "    if rows_cols:\n",
    "        num_row = len(dataset)\n",
    "        num_cols = len(dataset[0])\n",
    "        print('Dataset contains : \\nRows {0} \\nColumns {1}'.format(num_row, num_cols))\n",
    "        \n",
    "print(explore_data(hn, 0, 6, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Ask HN and Show HN Posts\n",
    "\n",
    "We are interested only by post titles that start with `Ask H` or `Show H`. So we will exploit only the rows that are refering to these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139 titles from Ask category\n",
      "10158 titles from Show category\n",
      "273822 titles from Other categories\n"
     ]
    }
   ],
   "source": [
    "#creating empty lists to store our data\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#filling up the list with relevant data\n",
    "for row in hn:\n",
    "    #lowercasing to match needed pattern\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('{0} titles from Ask category\\n{1} titles from Show category\\n{2} titles from Other categories'.format(len(ask_posts), len(show_posts), len(other_posts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the average for comments and points\n",
    "\n",
    "Below we're going to check which of the categories receives the most of comments/points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_num(dataset, num_row):\n",
    "    #initialiaziting counter to 0\n",
    "    total_num = 0\n",
    "    for row in dataset:\n",
    "        num = int(row[num_row])\n",
    "        #cumming up all the comments\n",
    "        total_num += num\n",
    "    #returning the average\n",
    "    return total_num / len(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for :\n",
      " Ask titles  10.39:\n",
      " Show titles is 4.89\n"
     ]
    }
   ],
   "source": [
    "avg_ask_comments = avg_num(ask_posts, 4)\n",
    "avg_show_comments = avg_num(show_posts, 4)\n",
    "print('The average number of comments for :\\n Ask titles  {0:.2f}:\\n Show titles is {1:.2f}'.format(avg_ask_comments, avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the `Ask` section has more comments. These post submissions imply that other users will provide answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of points for :\n",
      " Ask titles  11.31:\n",
      " Show titles is 14.84\n"
     ]
    }
   ],
   "source": [
    "avg_ask_points = avg_num(ask_posts, 3)\n",
    "avg_show_points = avg_num(show_posts, 3)\n",
    "print('The average number of points for :\\n Ask titles  {0:.2f}:\\n Show titles is {1:.2f}'.format(avg_ask_points, avg_show_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the points, people tend to upvote the Show titles more.\n",
    "\n",
    "That's why we are going evaluate our `Ask titles` by comments and `Show titles` by points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular time for posting\n",
    "\n",
    "Below we're going to explore if posts created at a certain time are attracting more comments/points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attention(dataset, col_time, col_att):\n",
    "    result_list = []\n",
    "    for row in dataset:\n",
    "        #saving creation time\n",
    "        time_create = row[col_time]\n",
    "        #saving the number of comments/points\n",
    "        num = int(row[col_att])\n",
    "        #appending in a form of list\n",
    "        result_list.append([time_create, num])\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis we're going to extract following pairs :\n",
    "- **hour-comments** from `ask_posts`\n",
    "- **hour-points** from `show_posts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_hour_comm = extract_attention(ask_posts, -1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hour_points = extract_attention(show_posts, -1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're going to create 2 dictionnaries that we will fill with specific information:\n",
    " * `counts_by_hour` - the number of ask posts created during each hour of the da`\n",
    " * `comments_by_hour` - the number of comments ask posts created at each hour received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_by_hour(result_list, time_col, att_col):\n",
    "    #number of total posts by hour\n",
    "    counts_by_hour = {}\n",
    "    #number of total comments or points by hour\n",
    "    att_by_hour = {}\n",
    "\n",
    "    #defining zones\n",
    "    from_zone = tz.gettz('EST')\n",
    "    to_zone = tz.gettz('CET')\n",
    "    \n",
    "    for row in result_list:\n",
    "        time_create = row[0]\n",
    "        num_att = row[1]\n",
    "        #parsing the time into a datetime object\n",
    "        time_obj = dt.datetime.strptime(time_create, '%m/%d/%Y %H:%M')\n",
    "        #assigning time info\n",
    "        utc = time_obj.replace(tzinfo=from_zone)\n",
    "        #assigning local time\n",
    "        local = utc.astimezone(to_zone)\n",
    "        #extracting only the hour\n",
    "        hour = dt.datetime.strftime(local, '%H')\n",
    "        if hour not in counts_by_hour:\n",
    "            counts_by_hour[hour] = 1\n",
    "            att_by_hour[hour] = num_att\n",
    "        else:\n",
    "            counts_by_hour[hour] += 1\n",
    "            att_by_hour[hour] += num_att  \n",
    "    return counts_by_hour, att_by_hour\n",
    "            \n",
    "ask_posts_by_hour, ask_comments_by_hour = attention_by_hour(ask_hour_comm, -1, 4)\n",
    "show_posts_by_hour, show_points_by_hour = attention_by_hour(show_hour_points, -1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Titles :\n",
      "Posts per hour :  [('00', 628), ('01', 576), ('02', 546), ('03', 502), ('04', 497), ('05', 361), ('06', 317), ('07', 278), ('08', 288), ('09', 272), ('10', 259), ('11', 216), ('12', 209), ('13', 231), ('14', 241), ('15', 259), ('16', 234), ('17', 292), ('18', 305), ('19', 380), ('20', 484), ('21', 557), ('22', 651), ('23', 556)]\n",
      "\n",
      "\n",
      "Ask Titles :\n",
      "Comments per hour :  [('00', 6372), ('01', 4584), ('02', 3719), ('03', 5165), ('04', 4008), ('05', 2888), ('06', 2054), ('07', 2537), ('08', 1879), ('09', 2870), ('10', 2213), ('11', 2476), ('12', 1545), ('13', 1411), ('14', 1847), ('15', 2270), ('16', 1727), ('17', 2880), ('18', 3211), ('19', 4837), ('20', 7062), ('21', 10661), ('22', 13266), ('23', 3504)]\n"
     ]
    }
   ],
   "source": [
    "print('Ask Titles :\\nPosts per hour : ', sorted(ask_posts_by_hour.items()))\n",
    "print('\\n')\n",
    "print('Ask Titles :\\nComments per hour : ', sorted(ask_comments_by_hour.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show Titles :\n",
      "Posts per hour :  [('00', 697), ('01', 641), ('02', 548), ('03', 484), ('04', 378), ('05', 363), ('06', 314), ('07', 263), ('08', 211), ('09', 201), ('10', 212), ('11', 181), ('12', 179), ('13', 194), ('14', 277), ('15', 305), ('16', 304), ('17', 371), ('18', 443), ('19', 541), ('20', 659), ('21', 772), ('22', 851), ('23', 769)]\n",
      "\n",
      "\n",
      "Show Titles :\n",
      "Points per hour :  [('00', 9864), ('01', 8943), ('02', 8467), ('03', 7384), ('04', 5175), ('05', 4951), ('06', 3888), ('07', 3982), ('08', 3632), ('09', 1499), ('10', 3084), ('11', 1888), ('12', 1902), ('13', 3273), ('14', 4294), ('15', 4288), ('16', 3677), ('17', 5285), ('18', 9919), ('19', 10240), ('20', 10041), ('21', 11581), ('22', 11431), ('23', 12093)]\n"
     ]
    }
   ],
   "source": [
    "print('Show Titles :\\nPosts per hour : ', sorted(show_posts_by_hour.items()))\n",
    "print('\\n')\n",
    "print('Show Titles :\\nPoints per hour : ', sorted(show_points_by_hour.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this structured information by hour, we need to find out \n",
    "* the average comments by post generated by hour from Ask Titles\n",
    "* the average points by post generated by hour from Show Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_by_hour(attention_by_hour, counts_by_hour):   \n",
    "    avg = []\n",
    "    for hour in attention_by_hour:\n",
    "        #appending the hour and the number of coments devided by the number of posts\n",
    "        avg.append([hour, attention_by_hour[hour] / counts_by_hour[hour]])\n",
    "    return avg\n",
    "\n",
    "#average comments by hour from Ask Titles\n",
    "ask_avg_comm = avg_by_hour(ask_comments_by_hour, ask_posts_by_hour)\n",
    "#average points by hour from Show Titles\n",
    "show_avg_points = avg_by_hour(show_points_by_hour, show_posts_by_hour) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09', 10.551470588235293]\n",
      "\n",
      "\n",
      "['08', 6.524305555555555]\n",
      "\n",
      "\n",
      "['05', 8.0]\n",
      "\n",
      "\n",
      "['04', 8.064386317907445]\n",
      "\n",
      "\n",
      "['02', 6.811355311355311]\n",
      "\n",
      "\n",
      "['00', 10.146496815286625]\n",
      "\n",
      "\n",
      "['22', 20.377880184331797]\n",
      "\n",
      "\n",
      "['21', 19.14003590664273]\n",
      "\n",
      "\n",
      "['20', 14.590909090909092]\n",
      "\n",
      "\n",
      "['18', 10.527868852459017]\n",
      "\n",
      "\n",
      "['17', 9.863013698630137]\n",
      "\n",
      "\n",
      "['16', 7.380341880341881]\n",
      "\n",
      "\n",
      "['14', 7.66390041493776]\n",
      "\n",
      "\n",
      "['10', 8.544401544401545]\n",
      "\n",
      "\n",
      "['06', 6.479495268138801]\n",
      "\n",
      "\n",
      "['03', 10.288844621513944]\n",
      "\n",
      "\n",
      "['23', 6.302158273381295]\n",
      "\n",
      "\n",
      "['15', 8.764478764478765]\n",
      "\n",
      "\n",
      "['07', 9.12589928057554]\n",
      "\n",
      "\n",
      "['01', 7.958333333333333]\n",
      "\n",
      "\n",
      "['19', 12.728947368421053]\n",
      "\n",
      "\n",
      "['11', 11.462962962962964]\n",
      "\n",
      "\n",
      "['13', 6.108225108225108]\n",
      "\n",
      "\n",
      "['12', 7.392344497607655]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(explore_data(ask_avg_comm, 0, len(ask_avg_comm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['07', 15.140684410646388]\n",
      "\n",
      "\n",
      "['06', 12.382165605095542]\n",
      "\n",
      "\n",
      "['03', 15.256198347107437]\n",
      "\n",
      "\n",
      "['02', 15.450729927007298]\n",
      "\n",
      "\n",
      "['01', 13.951638065522621]\n",
      "\n",
      "\n",
      "['23', 15.725617685305592]\n",
      "\n",
      "\n",
      "['21', 15.001295336787564]\n",
      "\n",
      "\n",
      "['17', 14.245283018867925]\n",
      "\n",
      "\n",
      "['16', 12.095394736842104]\n",
      "\n",
      "\n",
      "['15', 14.059016393442622]\n",
      "\n",
      "\n",
      "['13', 16.871134020618555]\n",
      "\n",
      "\n",
      "['10', 14.547169811320755]\n",
      "\n",
      "\n",
      "['04', 13.69047619047619]\n",
      "\n",
      "\n",
      "['00', 14.152080344332855]\n",
      "\n",
      "\n",
      "['22', 13.432432432432432]\n",
      "\n",
      "\n",
      "['18', 22.390519187358915]\n",
      "\n",
      "\n",
      "['14', 15.501805054151625]\n",
      "\n",
      "\n",
      "['11', 10.430939226519337]\n",
      "\n",
      "\n",
      "['20', 15.236722306525039]\n",
      "\n",
      "\n",
      "['19', 18.927911275415898]\n",
      "\n",
      "\n",
      "['08', 17.213270142180093]\n",
      "\n",
      "\n",
      "['05', 13.639118457300276]\n",
      "\n",
      "\n",
      "['09', 7.45771144278607]\n",
      "\n",
      "\n",
      "['12', 10.625698324022347]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(explore_data(show_avg_points, 0, len(show_avg_points)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our nex step will be sorting the data by comments/points in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_sort(avg_by_hour):\n",
    "    swap_avg_by_hour = []\n",
    "    for row in avg_by_hour:\n",
    "        #appending swapped columns\n",
    "        swap_avg_by_hour.append([row[1], row[0]])\n",
    "    sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "    return sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours(CET) for Ask Posts Comments\n",
      "22:00: 20.38 average comments per post\n",
      "21:00: 19.14 average comments per post\n",
      "20:00: 14.59 average comments per post\n",
      "19:00: 12.73 average comments per post\n",
      "11:00: 11.46 average comments per post\n",
      "09:00: 10.55 average comments per post\n"
     ]
    }
   ],
   "source": [
    "ask_comm_sort = swap_sort(ask_avg_comm)\n",
    "\n",
    "print('Top 5 Hours(CET) for Ask Posts Comments')\n",
    "for row in ask_comm_sort[:6]:\n",
    "    hour = row[1]\n",
    "    #parsing the string into datetime oject\n",
    "    hour_obj = dt.datetime.strptime(hour, '%H')\n",
    "    #spectifying format for datettime str\n",
    "    hour_str = hour_obj.strftime('%H:%M')\n",
    "    avg_comm = row [0]\n",
    "    print('{}: {:.2f} average comments per post'.format(hour_str, avg_comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours(CET) for Show Posts Comments\n",
      "18:00: 22.39 average comments per post\n",
      "19:00: 18.93 average comments per post\n",
      "08:00: 17.21 average comments per post\n",
      "13:00: 16.87 average comments per post\n",
      "23:00: 15.73 average comments per post\n",
      "14:00: 15.50 average comments per post\n"
     ]
    }
   ],
   "source": [
    "show_points_sort = swap_sort(show_avg_points)\n",
    "\n",
    "print('Top 5 Hours(CET) for Show Posts Comments')\n",
    "for row in show_points_sort[:6]:\n",
    "    hour = row[1]\n",
    "    #parsing the string into datetime oject\n",
    "    hour_obj = dt.datetime.strptime(hour, '%H')\n",
    "    #spectifying format for datettime str\n",
    "    hour_str = hour_obj.strftime('%H:%M')\n",
    "    avg_comm = row [0]\n",
    "    print('{}: {:.2f} average comments per post'.format(hour_str, avg_comm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments popular submissions and points popular submissions are not popular at the same time.\n",
    "\n",
    "It's better to post your question between 19:00-23:00(CET). You have more chances to get the maximum of commetns.\n",
    "\n",
    "If you want to share something and want people to vote for your post you're better posting mostly between 18:00-20:00 and 13:00-15:00 or try early in the morning between 08:00-09:00."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
