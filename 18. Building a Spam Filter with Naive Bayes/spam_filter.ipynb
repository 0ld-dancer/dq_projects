{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f732ce",
   "metadata": {},
   "source": [
    "## Spam Filter with Naive Bayes\n",
    "\n",
    "![Image](https://ampjar.com/wp-content/uploads/2019/07/HERO-avoid-spam-filters@2x.png)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "To classify messages as spam or non-spam using the naive bayes algorithm, we basically need follow these steps:\n",
    "\n",
    "* Learns how humans classify messages\n",
    "* Uses that human knowledge to estimate probabilities for new messages (spam and non-spam)\n",
    "* Classifies a new message based on these probability values\n",
    "\n",
    "In this project we'll be working with the data set provided by [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can download data set and readme download from this link and also get data set information.\n",
    "\n",
    "There are 5,572 SMS messages that are already classified by humans. Let's read it and take a quick look on the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d7221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classified_sms = pd.read_csv('SMSSpamCollection',\n",
    "                            sep='\\t',\n",
    "                            header=None,\n",
    "                            names=['Label', 'SMS'])\n",
    "\n",
    "classified_sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660efaa2",
   "metadata": {},
   "source": [
    "Let's find now what percentage of the messages is spam and what isn't (\"ham\" means non-spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc15dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13.4% spam messages and 86.6% non-spam messages in the data set\n"
     ]
    }
   ],
   "source": [
    "total_persentages = classified_sms['Label'].value_counts(normalize=True)\n",
    "\n",
    "print('''There are {:.1%} spam messages and {:.1%} non-spam messages in the data set'''\n",
    "      .format(total_persentages[1], total_persentages[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c153fa",
   "metadata": {},
   "source": [
    "### Building the filter\n",
    "\n",
    "#### Test preparation\n",
    "\n",
    "When creating software, it's a good rule to think over tests in advance. In this case we should split our data set into two parts:\n",
    "* training set (about 80% of the dataset)\n",
    "* test set (about 20% of the dataset)\n",
    "\n",
    "We'll create the spam filter using training set only. Once we have it, we'll apply the algorithm on testing set and compare  results with the human classificatioan. Our goal here is accuracy greater than **80%**.\n",
    "\n",
    "To ensure that spam and ham messages are spread properly throughout the datasets we'll randomize all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666486ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize whole data set\n",
    "classified_sms.sample(frac=1, random_state=1)\n",
    "\n",
    "#Index to split with\n",
    "split_on = round(len(classified_sms) * 0.8)\n",
    "train_set = classified_sms.iloc[:split_on, :].copy()\n",
    "test_set = classified_sms.iloc[split_on:, :].copy()\n",
    "\n",
    "#Reset index\n",
    "train_set.reset_index(inplace=True, drop=True)\n",
    "test_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ed229",
   "metadata": {},
   "source": [
    "Let's check the spam and ham ratio in these new sets. It should be similar to what we have in the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f927b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data set: 13.4% spam messages and 86.6% non-spam messages\n",
      "Train set: 13.5% spam messages and 86.5% non-spam messages\n",
      "Test set: 13.0% spam messages and 87.0% non-spam messages\n"
     ]
    }
   ],
   "source": [
    "train_persentages = train_set['Label'].value_counts(normalize=True)\n",
    "test_persentages = test_set['Label'].value_counts(normalize=True)\n",
    "\n",
    "print('''Full data set: {:.1%} spam messages and {:.1%} non-spam messages\n",
    "Train set: {:.1%} spam messages and {:.1%} non-spam messages\n",
    "Test set: {:.1%} spam messages and {:.1%} non-spam messages'''\n",
    "      .format(total_persentages[1], total_persentages[0],\n",
    "             train_persentages[1], train_persentages[0],\n",
    "             test_persentages[1], test_persentages[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2112a",
   "metadata": {},
   "source": [
    "Everything looks fine.\n",
    "\n",
    "#### Data cleaning\n",
    "\n",
    "We want to classify messages by the words in them so we need to convert them into sets of words. It means:\n",
    "* Remove any punctuation\n",
    "* Reduce everything to the lowercase\n",
    "* Split the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f80655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, ve, told, you, everything, will, stop, jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>[or, i, guess, lt, gt, min]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, home, ard, wat, time, will, u, reach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>[storming, msg, wen, u, lift, d, phne, u, say,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ham</td>\n",
       "      <td>[if, you, want, to, mapquest, it, or, somethin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  [go, until, jurong, point, crazy, available, o...\n",
       "1      ham                     [ok, lar, joking, wif, u, oni]\n",
       "2     spam  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3      ham  [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4      ham  [nah, i, don, t, think, he, goes, to, usf, he,...\n",
       "...    ...                                                ...\n",
       "4453   ham  [i, ve, told, you, everything, will, stop, jus...\n",
       "4454   ham                        [or, i, guess, lt, gt, min]\n",
       "4455   ham       [i, m, home, ard, wat, time, will, u, reach]\n",
       "4456   ham  [storming, msg, wen, u, lift, d, phne, u, say,...\n",
       "4457   ham  [if, you, want, to, mapquest, it, or, somethin...\n",
       "\n",
       "[4458 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.replace(\n",
    "    r'\\W', ' ',regex=True).str.lower().str.split()\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6f152",
   "metadata": {},
   "source": [
    "Now we should create a list of unique words - the **vocabulary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba82f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7813"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "for message in train_set['SMS']:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "#Remove duplicates and return the list\n",
    "vocabulary_set = set(vocabulary)\n",
    "vocabulary = list(vocabulary_set)\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a04d",
   "metadata": {},
   "source": [
    "There are 7813 words in the vocabulary!\n",
    "\n",
    "Now "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
