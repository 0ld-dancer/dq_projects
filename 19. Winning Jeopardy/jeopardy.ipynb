{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fe2d99",
   "metadata": {},
   "source": [
    "## Winning Jeopardy!\n",
    "\n",
    "![Image](https://www.nerdwallet.com/assets/blog/wp-content/uploads/2015/08/Winning-money.png)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "[Jeopardy](https://en.wikipedia.org/wiki/Jeopardy!) is a popular TV show in the US where participants answer questions to win money. In this project we'll try to find a way to become the winner and get as much money as possible.\n",
    "\n",
    "We'll be working with the data set from [reddit](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). It contains **216930** questions and other info. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451d855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date      Round                         Category  Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv', parse_dates=[' Air Date'])\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf5301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Show Number  216930 non-null  int64         \n",
      " 1    Air Date    216930 non-null  datetime64[ns]\n",
      " 2    Round       216930 non-null  object        \n",
      " 3    Category    216930 non-null  object        \n",
      " 4    Value       216930 non-null  object        \n",
      " 5    Question    216930 non-null  object        \n",
      " 6    Answer      216928 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ec081",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "Before we start let's clean some mess. Several columns have spaces in front. Let's fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e32b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old \n",
      " Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n",
      "Fixed \n",
      " Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols_to_fix = jeopardy.columns\n",
    "print('Old \\n', cols_to_fix)\n",
    "\n",
    "cols_to_fix = cols_to_fix.str.replace(r'^ ', '', regex=True)\n",
    "print('Fixed \\n',cols_to_fix)\n",
    "\n",
    "jeopardy.columns = cols_to_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e79f04",
   "metadata": {},
   "source": [
    "Also let's normalize strings in the `Question` and `Answer` columns. By that I mean:\n",
    "* Everyword should be in lowercase\n",
    "* No punctuation\n",
    "\n",
    "The `re` library will help us with that. But we are missing two values in the `Answer` column, so let's remove these rows first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55d49bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clean_question clean_answer\n",
       "0  for the last 8 years of his life galileo was u...   copernicus\n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe\n",
       "2  the city of yuma in this state has a record av...      arizona\n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds\n",
       "4  signer of the dec of indep framer of the const...   john adams"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "jeopardy.dropna(subset=['Answer'], inplace=True)\n",
    "\n",
    "def clean_qa(string):\n",
    "    '''\n",
    "    Take a string and return it in lowercase and\n",
    "    without any punctuation \n",
    "    '''\n",
    "    string = string.lower()\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    return string\n",
    "\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(clean_qa)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(clean_qa)\n",
    "jeopardy[['clean_question', 'clean_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fdbe6",
   "metadata": {},
   "source": [
    "We also can turn `Value` column to the numeric to allow us to manipulate it easier. But we must remove **\\$** and **,** signs first.\n",
    "\n",
    "Some values are missing, we'll replace them with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e4c57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: clean_value, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_value(string):\n",
    "    '''\n",
    "    Take a string, remove $ and , signs and try to covert it to int\n",
    "    \n",
    "    If can't convert return 0\n",
    "    '''\n",
    "    string = re.sub(r'[$,]', '', string)\n",
    "    \n",
    "    try:\n",
    "        string = int(string)\n",
    "    except:\n",
    "        string = 0\n",
    "        \n",
    "    return string\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(clean_value)\n",
    "jeopardy['clean_value'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880556d5",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "* How often the answer can be used for a question\n",
    "* How often questions are repeated\n",
    "\n",
    "#### The answer from the question\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. Also we'll remove `The` from count due to it's commonly found in answers and questions, but doesn't have any meaningful use.\n",
    "\n",
    "Let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9dd9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05792123724515945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: answer_in_question, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_match(row):\n",
    "    '''\n",
    "    Take a row from dataframe and count how many\n",
    "    times word from answer is in also in question\n",
    "    \n",
    "    Return relative result\n",
    "    '''\n",
    "    split_question = row['clean_question'].split()\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    #Remove `the` from answer if it's in there\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "        \n",
    "    if split_answer:\n",
    "        for word in split_answer:\n",
    "            if word in split_question:\n",
    "                match_count += 1\n",
    "                \n",
    "        return match_count / len(split_answer)\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(count_match, axis=1)\n",
    "print(jeopardy['answer_in_question'].mean())\n",
    "jeopardy['answer_in_question'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392746cb",
   "metadata": {},
   "source": [
    "As we can see only **5.79%** words from the answer are also in the question on average. It means that we can't hope to find the right answer just by hearing the question. Probably we should study.\n",
    "\n",
    "#### Repeated questions\n",
    "\n",
    "So we want to investigate how often new questions are repeats of older ones. For that purpose we'll:\n",
    "* go from the olderest questions to the most recent\n",
    "* look for any word that has 6 characters at least\n",
    "* add this word to the kind of vocabulary\n",
    "* count how many times word's arleady occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806eb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8721734034757384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84523    0.0\n",
       "84565    0.0\n",
       "84566    0.0\n",
       "84567    0.0\n",
       "84568    0.0\n",
       "Name: question_overlap, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sord df by date first\n",
    "jeopardy.sort_values(by=['Air Date'], inplace=True)\n",
    "\n",
    "#Prepare the dictionary\n",
    "terms_used = {}\n",
    "\n",
    "def overlap_count(question):\n",
    "    '''\n",
    "    Take a question, remove all short words (< 6 chars)\n",
    "    and make up a dictionary of unique words\n",
    "    \n",
    "    Return relative overlap number\n",
    "    '''\n",
    "    split_question = question.split()\n",
    "    \n",
    "    #Remove short words (< 6 char)\n",
    "    split_question = [word for word in split_question if len(word)>5]\n",
    "    \n",
    "    #Count the occurrence of word\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    \n",
    "    #Fill the dictionary\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            terms_used[word] += 1\n",
    "        else:\n",
    "            terms_used[word] = 1\n",
    "    \n",
    "    if len(split_question) != 0:\n",
    "        overlap = match_count / len(split_question)\n",
    "        return overlap\n",
    "    else:\n",
    "        return match_count\n",
    "        \n",
    "jeopardy['question_overlap'] = jeopardy['clean_question'].apply(overlap_count)\n",
    "\n",
    "print(jeopardy['question_overlap'].mean())\n",
    "jeopardy['question_overlap'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a9e8b",
   "metadata": {},
   "source": [
    "There is about **87%** overlap between terms in new questions and old questions. So we can use old questions to prepare to the game.\n",
    "\n",
    "But this set include about **10%** of all jeopardy question. And we looked only on separate words but not phrases. Using only overlaping question isn't the ultimate solution.\n",
    "\n",
    "#### Question value\n",
    "\n",
    "We could deside to pay attention to the high value question only. Given that we must separate all questions into two categories, for example:\n",
    "* low value - any question worth less than \\$800\n",
    "* high value - any question worth \\$800 or more\n",
    "\n",
    "Then we can find which terms correspond to the high-value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d76f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84523    0\n",
       "84565    1\n",
       "84566    1\n",
       "84567    1\n",
       "84568    1\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def high_low(value):\n",
    "    '''\n",
    "    Put a label on the question depends on it's value\n",
    "    '''\n",
    "    if value < 800:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "jeopardy['high_value'] = jeopardy['clean_value'].apply(high_low)\n",
    "jeopardy['high_value'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6141ee",
   "metadata": {},
   "source": [
    "Now we can start to count word occurrences in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b422efcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [5, 8],\n",
       " [1, 0],\n",
       " [2, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the dictionary\n",
    "terms_high_low = {w:[0,0] for w in terms_used.keys()}\n",
    "\n",
    "def high_low_count(row):\n",
    "    '''\n",
    "    Takes a question, removes all short words (< 6 chars)\n",
    "    and makes up a dictionary of unique words according\n",
    "    question value\n",
    "    \n",
    "    Returns nothing, updates dict\n",
    "    '''\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    #Remove short words (< 6 char)\n",
    "    split_question = [word for word in split_question if len(word)>5]\n",
    "    \n",
    "    #Fill the dictionary\n",
    "    if row['high_value'] == 1:\n",
    "        for word in split_question:\n",
    "            terms_high_low[word][0] += 1\n",
    "    else:\n",
    "        for word in split_question:\n",
    "            terms_high_low[word][1] += 1\n",
    "    \n",
    "    return None\n",
    "\n",
    "#Update the dict\n",
    "jeopardy.apply(high_low_count, axis=1)\n",
    "\n",
    "import random\n",
    "\n",
    "#Take 10 random terms\n",
    "random.seed(0)\n",
    "comparison_terms = random.sample(tuple(terms_used), k=10)\n",
    "\n",
    "observed_expected = []\n",
    "for word in comparison_terms:\n",
    "    result = terms_high_low[word]\n",
    "    observed_expected.append(result)\n",
    "    \n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e15bc3",
   "metadata": {},
   "source": [
    "Now we've found the observed counts for the chi-squared test.\n",
    "\n",
    "#### Chi-Squared test\n",
    "\n",
    "We are almost reasy for chi-squared test, we just need the expected values. We can get them by using total terms proportions and overall number of high-value and low-value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44695968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.754427963702829, pvalue=0.3850779221952164),\n",
       " Power_divergenceResult(statistic=1.3255076006089066, pvalue=0.24960599546245862),\n",
       " Power_divergenceResult(statistic=0.754427963702829, pvalue=0.3850779221952164),\n",
       " Power_divergenceResult(statistic=0.754427963702829, pvalue=0.3850779221952164),\n",
       " Power_divergenceResult(statistic=0.10931382247720889, pvalue=0.7409266954088055),\n",
       " Power_divergenceResult(statistic=1.3255076006089066, pvalue=0.24960599546245862),\n",
       " Power_divergenceResult(statistic=2.651015201217813, pvalue=0.10348378920405768),\n",
       " Power_divergenceResult(statistic=1.3255076006089066, pvalue=0.24960599546245862),\n",
       " Power_divergenceResult(statistic=0.754427963702829, pvalue=0.3850779221952164),\n",
       " Power_divergenceResult(statistic=1.3255076006089066, pvalue=0.24960599546245862)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.mstats import chisquare\n",
    "\n",
    "#Numbers of question in each category\n",
    "total_high = jeopardy['high_value'].sum()\n",
    "total_low = len(jeopardy) - total_high\n",
    "\n",
    "chi_squared = []\n",
    "for pair in observed_expected:\n",
    "    pair_sum = pair[0] + pair[1]\n",
    "    total_prop = pair_sum / len(jeopardy)\n",
    "    \n",
    "    #Expected values\n",
    "    high_exp = total_high * total_prop\n",
    "    low_exp = total_low * total_prop\n",
    "    \n",
    "    chi_result = chisquare(pair, [high_exp, low_exp])\n",
    "    chi_squared.append(chi_result)\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793bf02f",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Also most of the frequencies were low, so the chi-squared test isn't as valid.\n",
    "\n",
    "#### High frequency chi-Squared\n",
    "\n",
    "It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9954a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "called       5461\n",
       "country      4868\n",
       "became       3162\n",
       "played       3011\n",
       "president    3010\n",
       "before       2909\n",
       "american     2837\n",
       "capital      2772\n",
       "famous       2497\n",
       "french       2488\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_used = pd.Series(terms_used).sort_values(ascending=False)\n",
    "top_used.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a0c0e",
   "metadata": {},
   "source": [
    "Let's apply chi-squared test for top 10 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "563b2765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'called': Power_divergenceResult(statistic=15.42649873971819, pvalue=8.577700638823399e-05),\n",
       " 'country': Power_divergenceResult(statistic=0.03755079185319079, pvalue=0.8463479388356194),\n",
       " 'became': Power_divergenceResult(statistic=0.13680455884183906, pvalue=0.7114786079420359),\n",
       " 'played': Power_divergenceResult(statistic=7.98615820916753, pvalue=0.004713633071089914),\n",
       " 'president': Power_divergenceResult(statistic=2.2058789247447224, pvalue=0.13748551321649827),\n",
       " 'before': Power_divergenceResult(statistic=0.9415299409384695, pvalue=0.33188469035879187),\n",
       " 'american': Power_divergenceResult(statistic=25.84258518926645, pvalue=3.70424931415654e-07),\n",
       " 'capital': Power_divergenceResult(statistic=0.5312119125428831, pvalue=0.4660977915180684),\n",
       " 'famous': Power_divergenceResult(statistic=0.703109189836983, pvalue=0.4017409294552422),\n",
       " 'french': Power_divergenceResult(statistic=105.06948798342381, pvalue=1.1792691791457759e-24)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = top_used.iloc[:10]\n",
    "\n",
    "chi_squared_top = {}\n",
    "\n",
    "for word in top_10.index:    \n",
    "    total_prop = top_10[word] / len(jeopardy)\n",
    "\n",
    "    #Expected values\n",
    "    high_exp = total_high * total_prop\n",
    "    low_exp = total_low * total_prop\n",
    "    \n",
    "    chi_result = chisquare(terms_high_low[word], [high_exp, low_exp])\n",
    "    chi_squared_top[word] = chi_result\n",
    "    \n",
    "chi_squared_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d34fe",
   "metadata": {},
   "source": [
    "We'vw got statistically significant results (p<0.05) for a few words:\n",
    "* called\n",
    "* played\n",
    "* american\n",
    "* french\n",
    "\n",
    "Only two of them could make any sense but we can't tell the direction of differences between high and low value question only by chi-squared. Let's check values for both types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42c1451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american [1354, 1483]\n",
      "french [1323, 1165]\n"
     ]
    }
   ],
   "source": [
    "print('american', terms_high_low['american'])\n",
    "print('french', terms_high_low['french'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45823cc9",
   "metadata": {},
   "source": [
    "### Conlusion\n",
    "\n",
    "The first value is the number of occurs in high value questions, second - low value questions. Word **`american`** occurs more often in **low value** question and word **`frensh`** is contrariwise - in **high value**.\n",
    "\n",
    "So we can't pick guaranteed strategy for winning Jeopardy just by using the statistically significant results from chi-squared test only. This task needs further exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
